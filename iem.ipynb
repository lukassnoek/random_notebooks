{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted encoding models, revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.base import RegressorMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.linalg import toeplitz\n",
    "from sklearn.discriminant_analysis import _cov, LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy import stats\n",
    "import pymc3 as pm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iem(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" Base class for Inverted Encoding Model. \"\"\"\n",
    "\n",
    "    def __init__(self, classify=True, score_func=None):\n",
    "        \"\"\" Initializes base class. \"\"\"\n",
    "        self.W = None  # estimated parameters\n",
    "        self.classify = classify\n",
    "\n",
    "    def _preproc(self, S):\n",
    "        \"\"\" Preprocesses stimulus features (S). \"\"\"\n",
    "        if self.classify and S.ndim == 1:\n",
    "            S = OneHotEncoder(sparse=False).fit_transform(S[:, np.newaxis])\n",
    "        elif not self.classify and S.ndim == 1:\n",
    "            S = np.c_[np.ones(S.shape[0]), S]\n",
    "\n",
    "        return S\n",
    "    \n",
    "    def _classify(self, S_pred):\n",
    "        \"\"\" Makes predictions categorical. \"\"\"\n",
    "        return np.argmax(S_pred, axis=0)\n",
    "\n",
    "    def fit(self, R, S):\n",
    "        \"\"\" Fits model (should be defined in child class). \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, R):\n",
    "        \"\"\" Predicts new stimuli based on responses\n",
    "        (should be defined in child class). \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def score(self, R, S):\n",
    "        \"\"\" Scores prediction. \"\"\"\n",
    "        S_pred = self.predict(R)\n",
    "        \n",
    "        if self.classify:\n",
    "            return np.mean(S_pred == S)\n",
    "\n",
    "class OlsIem(Iem):\n",
    "\n",
    "    def fit(self, R, S):\n",
    "        \n",
    "        S = self._preproc(S)\n",
    "        self.W = np.linalg.inv(S.T @ S) @ S.T @ R\n",
    "        return self\n",
    "\n",
    "    def predict(self, R):\n",
    "        S_pred = np.linalg.pinv(self.W @ self.W.T) @ self.W @ R.T\n",
    "        \n",
    "        if self.classify:\n",
    "            S_pred = self._classify(S_pred)\n",
    "\n",
    "        return S_pred\n",
    "\n",
    "\n",
    "class WlsIem(Iem):\n",
    "    \n",
    "    def fit(self, R, S):\n",
    "        \n",
    "        S = self._preproc(S)\n",
    "        self.W = np.linalg.inv(S.T @ S) @ S.T @ R\n",
    "        resids = R - S @ self.W\n",
    "        var_err = np.var(resids, axis=0)\n",
    "        omega = np.eye(resids.shape[1])\n",
    "        np.fill_diagonal(omega, var_err)\n",
    "        self.omega = np.linalg.inv(omega)\n",
    "        return self\n",
    "\n",
    "    def predict(self, R):\n",
    "        W, omega = self.W, self.omega\n",
    "        S_pred = np.linalg.pinv(W @ omega @ W.T) @ W @ omega @ R.T\n",
    "\n",
    "        if self.classify:\n",
    "            S_pred = self._classify(S_pred)\n",
    "\n",
    "        return S_pred\n",
    "\n",
    "    \n",
    "class GlsIem(Iem):\n",
    "    \n",
    "    def __init__(self, shrink_cov='auto', classify=True):\n",
    "        self.shrink_cov = shrink_cov\n",
    "        super().__init__(classify=classify)\n",
    "    \n",
    "    def fit(self, R, S):\n",
    "        \n",
    "        S = self._preproc(S)\n",
    "        self.W = np.linalg.inv(S.T @ S) @ S.T @ R\n",
    "        resids = R - S @ self.W\n",
    "        cov_err = _cov(resids, shrinkage=self.shrink_cov)\n",
    "        self.omega = np.linalg.inv(cov_err)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, R):\n",
    "        W, omega = self.W, self.omega\n",
    "        S_pred = np.linalg.pinv(W @ omega @ W.T) @ W @ omega @ R.T\n",
    "\n",
    "        if self.classify:\n",
    "            S_pred = self._classify(S_pred)\n",
    "\n",
    "        return S_pred\n",
    "\n",
    "\n",
    "class RidgeGlsIem(GlsIem):\n",
    "    \n",
    "    def __init__(self, alpha=1, classify=True, shrink_cov='auto'):\n",
    "        self.alpha = alpha\n",
    "        super().__init__(classify=classify, shrink_cov=shrink_cov)   \n",
    "\n",
    "    def predict(self, R):\n",
    "        \n",
    "        W, omega = self.W, self.omega\n",
    "        S_pred = (np.linalg.pinv(W @ omega @ W.T) + self.alpha*np.eye(W.shape[0])) @ W @ omega @ R.T\n",
    "\n",
    "        if self.classify:\n",
    "            S_pred = self._classify(S_pred)\n",
    "        \n",
    "        return S_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, categorical=True, N=100, P=4, K=50, sig_sq=1,\n",
    "                 rho=0.9, max_var=10, noise_model='ols', param_model='unif'):\n",
    "\n",
    "        self.categorical = categorical\n",
    "        self.N = N\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.sig_sq = sig_sq\n",
    "        self.rho = rho  # ar1 param\n",
    "        self.max_var = max_var\n",
    "        self.noise_model = noise_model\n",
    "        self.param_model = param_model\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "        N, P, K = self.N, self.P, self.K\n",
    "        S = self._generate_design()\n",
    "        eps = self._generate_noise()\n",
    "        W = self._generate_params()\n",
    "        R = S.dot(W) + eps\n",
    "\n",
    "        if self.categorical:\n",
    "            S = np.argmax(S, axis=1)\n",
    "\n",
    "        return S, R\n",
    "\n",
    "    def _generate_design(self):\n",
    "        \n",
    "        N, P = self.N, self.P\n",
    "        if self.categorical:\n",
    "            S_tmp = np.repeat(np.arange(P), N / P)[:, np.newaxis]\n",
    "            S = OneHotEncoder(sparse=False).fit_transform(S_tmp)\n",
    "        else:\n",
    "            S = np.random.normal(0, 1, size=(N, P))\n",
    "\n",
    "        return S\n",
    "\n",
    "    def _generate_noise(self):\n",
    "        \n",
    "        N, K = self.N, self.K\n",
    "        noise_mu = np.zeros(K)\n",
    "\n",
    "        if self.noise_model == 'ols':\n",
    "            noise_cov = np.identity(K)\n",
    "        elif self.noise_model in ['wls', 'gls', 'wgls']:\n",
    "\n",
    "            if self.noise_model == 'gls':\n",
    "                # assuming equal variance, but with non-zero covariance\n",
    "                noise_cov = self.rho ** toeplitz(np.arange(K))\n",
    "            else:\n",
    "                varz = np.random.uniform(0, self.max_var, size=K)\n",
    "                if self.noise_model == 'wls':\n",
    "                    noise_cov = np.diag(varz)\n",
    "                else:    \n",
    "                    corr_cov = self.rho ** toeplitz(np.arange(K))\n",
    "                    varz = varz[:, np.newaxis]\n",
    "                    noise_cov = np.sqrt(varz.dot(varz.T))\n",
    "                    noise_cov *= corr_cov\n",
    "\n",
    "        noise = np.random.multivariate_normal(noise_mu, self.sig_sq*noise_cov, size=N)\n",
    "        return noise\n",
    "    \n",
    "    def _generate_params(self):\n",
    "\n",
    "        P, K = self.P, self.K\n",
    "\n",
    "        params_mu = np.zeros(P)\n",
    "        if self.param_model == 'unif':\n",
    "            W = np.random.uniform(-.5, .5, size=(P, K))\n",
    "        elif self.param_model == 'ols':\n",
    "            params_cov = np.identity(P) / 10\n",
    "            W = np.random.multivariate_normal(params_mu, params_cov, size=K).T\n",
    "        elif self.param_model == 'gls':\n",
    "            params_cov = 0.5 ** toeplitz(np.arange(P))\n",
    "            W = np.random.multivariate_normal(params_mu, params_cov, size=K).T\n",
    "        elif self.param_model == 'wls':    \n",
    "            varz = np.random.uniform(0, 1, size=P)\n",
    "            params_cov = np.diag(varz)\n",
    "            W = np.random.multivariate_normal(params_mu, params_cov, size=K).T\n",
    "        elif self.param_model == 'wgls':\n",
    "            varz = np.random.uniform(0, 1, size=P)[:, np.newaxis]\n",
    "            params_cov = np.sqrt(varz.dot(varz.T))\n",
    "            params_cov *= 0.5 ** toeplitz(np.arange(P))\n",
    "            W = np.random.multivariate_normal(params_mu, params_cov, size=K).T\n",
    "            \n",
    "        return W\n",
    "    \n",
    "for categorical in [True, False]:\n",
    "    # print(\"categorical: %s\" % categorical)\n",
    "    for noise_model in ['ols', 'wls', 'gls', 'wgls']:\n",
    "        # print('\\t noise_model: %s' % noise_model)\n",
    "        for param_model in ['unif', 'ols', 'wls', 'gls', 'wgls']:\n",
    "            # print('\\t\\t param_model: %s' % param_model)\n",
    "            dgn = DataGenerator(categorical=categorical, N=100, P=2, K=50,\n",
    "                                sig_sq=1, noise_model=noise_model, param_model=param_model)\n",
    "            S, R = dgn.generate()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 200\n",
    "P = 2\n",
    "K = 100\n",
    "sig_sq = 10\n",
    "\n",
    "iters = 500\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "clfs = [OlsIem(), WlsIem(), GlsIem(), GaussianNB(), LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr')]\n",
    "for i, noise_model in enumerate(['ols', 'wls', 'gls', 'wgls']):\n",
    "    scores = np.zeros((iters, len(clfs)))\n",
    "    \n",
    "    for ii in range(iters):\n",
    "\n",
    "        S, R = DataGenerator(categorical=True, N=N, P=P, K=K, sig_sq=sig_sq,\n",
    "                             noise_model=noise_model).generate()\n",
    "        for iii, clf in enumerate(clfs):\n",
    "            scores[ii, iii] = cross_val_score(estimator=clf, X=R, y=S, cv=10).mean()\n",
    "\n",
    "    for ii in range(scores.shape[1]):\n",
    "        sns.distplot(scores[:, ii], ax=axes[i], hist=False, label=clfs[ii].__class__.__name__,\n",
    "                     kde_kws={'lw': 4})\n",
    "\n",
    "    axes[i].set_title('Noise model: %s' % noise_model)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
